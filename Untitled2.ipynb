{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+nFkmR1XIpu3/ffFWnfCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LM1997610/Fundamentals_DataScience/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1NycWiyuytbN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WISo-83T_Dd_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------\n",
        "# Hyper-parameters\n",
        "#--------------------------------\n",
        "input_size = 32 * 32 * 3\n",
        "hidden_size = [50]\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 200\n",
        "learning_rate = 15e-2 # 1e-3\n",
        "learning_rate_decay = 0.95\n",
        "reg=0.001\n",
        "num_training= 49000\n",
        "num_validation =1000\n",
        "train = True"
      ],
      "metadata": {
        "id": "zJWhMaM_-QKv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "015e-2"
      ],
      "metadata": {
        "id": "e745np2WWR5A",
        "outputId": "99c16134-60c4-40be-c9b7-e6a2bd463962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------\n",
        "# Load the CIFAR-10 dataset\n",
        "#-------------------------------------------------\n",
        "norm_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "cifar_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                           train=True,\n",
        "                                           transform=norm_transform,\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                          train=False,\n",
        "                                          transform=norm_transform)\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Prepare the training and validation splits\n",
        "#-------------------------------------------------\n",
        "mask = list(range(num_training))\n",
        "train_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "mask = list(range(num_training, num_training + num_validation))\n",
        "val_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Data loader\n",
        "#-------------------------------------------------\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "CJfmSVer9wuZ",
        "outputId": "23cc49f5-a986-4f34-ae63-124060b70e83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.normal_(0.0, 1e-3)\n",
        "        m.bias.data.fill_(0.)\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "#--------------------------------\n",
        "# Device configuration\n",
        "#--------------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n",
        "\n",
        "#--------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSkMRyuHyyMr",
        "outputId": "8a047694-7733-477d-e234-f687fbc7d612"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#======================================================================================\n",
        "# Q4: Implementing multi-layer perceptron in PyTorch\n",
        "#======================================================================================\n",
        "# So far we have implemented a two-layer network using numpy by explicitly\n",
        "# writing down the forward computation and deriving and implementing the\n",
        "# equations for backward computation. This process can be tedious to extend to\n",
        "# large network architectures\n",
        "#\n",
        "# Popular deep-learning libraries like PyTorch and Tensorflow allow us to\n",
        "# quickly implement complicated neural network architectures. They provide\n",
        "# pre-defined layers which can be used as building blocks to define our\n",
        "# network. They also enable automatic-differentiation, which allows us to\n",
        "# define only the forward pass and let the libraries perform back-propagation\n",
        "# using automatic differentiation.\n",
        "#\n",
        "# In this question we will implement a multi-layer perceptron using the PyTorch\n",
        "# library.  Please complete the code for the MultiLayerPerceptron, training and\n",
        "# evaluating the model. Once you can train the two layer model, experiment with\n",
        "# adding more layers and report your observations\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Fully connected neural network with one hidden layer\n",
        "#-------------------------------------------------\n",
        "\n",
        "class MultiLayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, num_classes):\n",
        "        super(MultiLayerPerceptron, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        layers = [nn.Linear(self.input_size, self.hidden_layers),   #Use the layers list to store a variable number of layers\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(self.hidden_layers, self.num_classes),\n",
        "                  nn.Softmax()]\n",
        "\n",
        "        # Enter the layers into nn.Sequential, so the model may \"see\" them\n",
        "        # Note the use of * in front of layers\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #################################################################################\n",
        "        # TODO: Implement the forward pass computations                                 #\n",
        "        # Note that you do not need to use the softmax operation at the end.            #\n",
        "        # Softmax is only required for the loss computation and the criterion used below#\n",
        "        # nn.CrossEntropyLoss() already integrates the softmax and the log loss together#\n",
        "        #################################################################################\n",
        "\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        out = self.layers[0](x)\n",
        "        out = self.layers[1](out)\n",
        "        out = self.layers[2](out)\n",
        "        #out = self.layers[3](out)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "EDKBw2ePy7fY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiLayerPerceptron(input_size, hidden_size[0], num_classes).to(device)"
      ],
      "metadata": {
        "id": "QvYAUDD6-wjA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model's state_dict:\")\n",
        "\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "metadata": {
        "id": "T2dE19V_8mBP",
        "outputId": "10043568-f991-483c-9c32-a8c9ee6aa944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "layers.0.weight \t torch.Size([50, 3072])\n",
            "layers.0.bias \t torch.Size([50])\n",
            "layers.2.weight \t torch.Size([10, 50])\n",
            "layers.2.bias \t torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train:\n",
        "    model.apply(weights_init)\n",
        "    model.train() #set dropout and batch normalization layers to training mode\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
        "\n",
        "    # Train the model\n",
        "    lr = learning_rate\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Move tensors to the configured device\n",
        "\n",
        "            images = images.reshape(-1,32*32*3)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "             #################################################################################\n",
        "            # TODO: Implement the training code                                             #\n",
        "            # 1. Pass the images to the model                                               #\n",
        "            # 2. Compute the loss using the output and the labels.                          #\n",
        "            # 3. Compute gradients and update the model using the optimizer                 #\n",
        "            # Use examples in https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
        "            #################################################################################\n",
        "\n",
        "            # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('\\nEpoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "UYnB0eSc-hj_",
        "outputId": "daf2c2c5-f9a5-45d6-c756-487e97bf409f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/245], Loss: 4.5683\n",
            "Epoch [1/10], Step [200/245], Loss: 2.2838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:12<01:53, 12.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Step [100/245], Loss: 90.9526\n",
            "Epoch [2/10], Step [200/245], Loss: 24.4792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:27<01:49, 13.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Step [100/245], Loss: 3.3153\n",
            "Epoch [3/10], Step [200/245], Loss: 2.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:41<01:36, 13.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Step [100/245], Loss: 91.4770\n",
            "Epoch [4/10], Step [200/245], Loss: 20.8678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:53<01:20, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Step [100/245], Loss: 1.9749\n",
            "Epoch [5/10], Step [200/245], Loss: 2.0175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:06<01:05, 13.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Step [100/245], Loss: 2.1806\n",
            "Epoch [6/10], Step [200/245], Loss: 8.3378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:18<00:51, 12.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Step [100/245], Loss: 60.3059\n",
            "Epoch [7/10], Step [200/245], Loss: 2.9439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:31<00:38, 12.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Step [100/245], Loss: 2.1348\n",
            "Epoch [8/10], Step [200/245], Loss: 2.0713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:44<00:25, 12.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Step [100/245], Loss: 37.1245\n",
            "Epoch [9/10], Step [200/245], Loss: 113.1205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [01:56<00:12, 12.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Step [100/245], Loss: 7.0567\n",
            "Epoch [10/10], Step [200/245], Loss: 1.8661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:09<00:00, 12.90s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to update the lr\n",
        "lr *= learning_rate_decay\n",
        "update_lr(optimizer, lr)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in tqdm(val_loader):\n",
        "        images = images.reshape(-1,32*32*3).to(device)\n",
        "        labels = labels.to(device)\n",
        "        ####################################################\n",
        "        # TODO: Implement the evaluation code              #\n",
        "        # 1. Pass the images to the model                  #\n",
        "        # 2. Get the most confident predicted class        #\n",
        "        ####################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        output= model(images)\n",
        "        _ , predicted = torch.max(output, 1)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print()\n",
        "    print('\\nValidataion accuracy is: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "AGkbK0dkNLMQ",
        "outputId": "b0c9ae32-bf80-43ec-80a0-b445a5dfc6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 21.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Validataion accuracy is: 31.4 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQVoobXrMk5F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#else:\n",
        "    # Run the test code once you have your by setting train flag to false\n",
        "    # and loading the best model\n",
        "\n",
        "#best_model = None\n",
        "#best_model = torch.load('model.ckpt')\n",
        "#best_model = model\n",
        "\n",
        "#model.load_state_dict(best_model)\n",
        "\n",
        "# Test the model\n",
        "model.eval() #set dropout and batch normalization layers to evaluation mode\n",
        "\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        images = images.reshape(-1, 32*32*3).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ####################################################\n",
        "        # TODO: Implement the evaluation code              #\n",
        "        # 1. Pass the images to the model                  #\n",
        "        # 2. Get the most confident predicted class        #\n",
        "        ####################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "        output= model(images)\n",
        "        _ , predicted = torch.max(output, 1)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if total == 1000:\n",
        "            break\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NxH5AA12NPyV",
        "outputId": "23b7adef-839e-4f78-f61b-514e5952a4e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1000 test images: 31.6 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-KVmkEHTKyX"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}